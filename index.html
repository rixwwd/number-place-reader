<!DOCTYPE html>
<html lang="ja">

<head>
  <meta charset="utf-8">
  <link href="https://cdn.jsdelivr.net/npm/normalize.css@8.0.1/normalize.css" rel="stylesheet" />
  <style>
    #input {
      position: static;
      width: 720px;
      height: 720px;
    }

    #camera {
      position: absolute;
      top: 0;
      left: 0;
      width: 720px;
      height: 720px;
    }

    #snapshotCanvas {
      position: absolute;
      top: 0;
      left: 0;
      width: 720px;
      height: 720px;
    }

    #inputCanvas {
      display: none;
    }

    #frameCanvas {
      position: absolute;
      top: 0;
      left: 0;
      width: 720px;
      height: 720px;
      z-index: 1;
    }
  </style>
  <script src="https://docs.opencv.org/4.10.0/opencv.js"></script>
  <script src='https://cdn.jsdelivr.net/npm/tesseract.js@5/dist/tesseract.min.js'></script>
</head>

<body>
  <div id="input">
    <canvas id="inputCanvas"></canvas>
    <video id="camera"></video>
    <canvas id="snapshotCanvas"></canvas>
    <canvas id="frameCanvas" width="720" height="720"></canvas>
  </div>
  <div>
    <button id="startCamera">カメラ開始</button>
    <button id="capture">撮影</button>
    <input id="selectImage" type="file" accept="image/*">
    <button id="process">処理開始</button>
  </div>
  <div>
    <p>モノクロ化</p>
    <canvas id="monoCanvas"></canvas>
  </div>
  <div>
    <p>枠の検出</p>
    <canvas id="contourCanvas"></canvas>
  </div>
  <div>
    <p>枠を抜き出す</p>
    <canvas id="cellsCanvas"></canvas>
  </div>
  <div>
    <p>文字の認識</p>
    <canvas id="digitCanvas"></canvas>
  </div>
  <script>
    const CANVAS_SIZE = 720;
    const FRAME_SIZE = 64 * 9;
    let videoStream;

    window.addEventListener('DOMContentLoaded', () => {
      const startCameraButton = document.getElementById('startCamera');
      startCameraButton.addEventListener('click', startCamera);
      const captureButton = document.getElementById('capture');
      captureButton.addEventListener('click', capture);
      const processButton = document.getElementById('process');
      processButton.addEventListener('click', process);

      const selectImage = document.getElementById('selectImage');
      selectImage.addEventListener('change', loadImageFromFile);

      drawFrameRectangle();
    });

    function loadImageFromFile() {
      const reader = new FileReader();
      reader.onload = () => {
        const img = new Image();
        img.onload = () => {
          const canvas = document.getElementById('snapshotCanvas');
          canvas.width = img.width;
          canvas.height = img.height;
          const ctx = canvas.getContext('2d');
          ctx.drawImage(img, 0, 0);

          loadFromSnapshotCanvas();
        };
        img.src = reader.result;
      };
      reader.readAsDataURL(selectImage.files[0]);
    }

    async function startCamera() {
      console.debug('startCamera');

      clearInputCanvas();

      const video = document.getElementById('camera');
      video.addEventListener('canplay', () => {
        console.debug('oncanplay');
        video.width = video.videoWidth;
        video.height = video.videoHeight;
      });

      const constraints = {
        audio: false,
        video: { width: CANVAS_SIZE, height: CANVAS_SIZE, facingMode: { ideal: 'environment' } }
      };
      await navigator.mediaDevices.getUserMedia(constraints)
        .then((stream) => {
          videoStream = stream;
          video.srcObject = stream;
          video.play();
        })
        .catch((err) => {
          console.error(`An error occurred: ${err}`);
        });
    }

    function clearInputCanvas() {
      const canvas = document.getElementById('snapshotCanvas');
      const context = canvas.getContext('2d');
      context.clearRect(0, 0, CANVAS_SIZE, CANVAS_SIZE);
    }
    function drawFrameRectangle() {
      const canvas = document.getElementById('frameCanvas');
      const context = canvas.getContext('2d');
      context.clearRect(0, 0, CANVAS_SIZE, CANVAS_SIZE);
      context.strokeStyle = 'rgb(0 255 0)';
      context.strokeRect((CANVAS_SIZE - FRAME_SIZE) / 2, (CANVAS_SIZE - FRAME_SIZE) / 2, FRAME_SIZE, FRAME_SIZE)
    }

    function capture() {

      const snapshotCanvas = document.getElementById('snapshotCanvas');
      const snapshotCtx = snapshotCanvas.getContext('2d');
      const video = document.getElementById('camera');
      snapshotCanvas.width = CANVAS_SIZE;
      snapshotCanvas.height = CANVAS_SIZE;
      snapshotCtx.drawImage(video, 0, 0);

      loadFromSnapshotCanvas();

      videoStream?.getTracks().forEach((track) => track.stop());
      videoStream = undefined;
    }

    function loadFromSnapshotCanvas() {
      const snapshotCanvas = document.getElementById('snapshotCanvas');
      const inputCanvas = document.getElementById('inputCanvas');
      inputCanvas.height = FRAME_SIZE;
      inputCanvas.width = FRAME_SIZE;
      const inputCtx = inputCanvas.getContext('2d');
      inputCtx.drawImage(
        snapshotCanvas,
        (CANVAS_SIZE - FRAME_SIZE) / 2, (CANVAS_SIZE - FRAME_SIZE) / 2, FRAME_SIZE, FRAME_SIZE,
        0, 0, FRAME_SIZE, FRAME_SIZE
      );
    }

    async function process() {
      const srcImg = cv.imread('inputCanvas');

      const monochromatizedImage = monochromatize(srcImg);
      cv.imshow('monoCanvas', monochromatizedImage);

      const frame = detectFrame(monochromatizedImage);
      if (frame) {
        const color = new cv.Scalar(0, 255, 0, 255);
        const v = new cv.MatVector();
        v.push_back(frame);
        const contourImg = new cv.Mat(monochromatizedImage.size(), cv.CV_8UC4);
        cv.cvtColor(monochromatizedImage, contourImg, cv.COLOR_GRAY2RGBA);
        cv.drawContours(contourImg, v, 0, color);
        cv.imshow('contourCanvas', contourImg);
        v.delete();

        const frameImg = extractFrame(monochromatizedImage, frame);
        cv.imshow('cellsCanvas', frameImg);
        await readDigit(document.getElementById('cellsCanvas'), document.getElementById('digitCanvas'));
        frameImg.delete();
      } else {
        console.log("枠を検出できなかった");
      }

      srcImg.delete();
      monochromatizedImage.delete();
      frame?.delete();
    }

    /**
     * モノクロ化
     * @param {cv.Mat} srcImg 入力画像
     * @preturn {cv.Mat} モノクロ化した画像
     */
    function monochromatize(srcImg) {
      const grayImg = new cv.Mat(FRAME_SIZE, FRAME_SIZE, cv.CV_8UC1);
      cv.cvtColor(srcImg, grayImg, cv.COLOR_BGR2GRAY);
      const monoImg = new cv.Mat(FRAME_SIZE, FRAME_SIZE, cv.CV_8UC1);
      cv.adaptiveThreshold(grayImg, monoImg, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY_INV, 31, 21);
      grayImg.delete();

      // 枠を抜き出す際の変形でノイズが広がらないよう、細かいノイズを除去しておく
      const removeNoiseImg = new cv.Mat(FRAME_SIZE, FRAME_SIZE, cv.CV_8U);
      const kernel = cv.Mat.ones(2, 2, cv.CV_8U);
      cv.morphologyEx(monoImg, removeNoiseImg, cv.MORPH_OPEN, kernel);
      kernel.delete();
      monoImg.delete()
      return removeNoiseImg;
    }

    /**
     * 枠の検出
     * @param {cv.Mat} srcImg 入力画像
     * @return {cv.Mat} 検出した枠の座標。検出できなかったときはnull。
     */
    function detectFrame(srcImg) {
      const contours = new cv.MatVector();
      const hierarchy = new cv.Mat();
      cv.findContours(srcImg, contours, hierarchy, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_TC89_L1);

      let maxArea = -1;
      let largeContour;
      for (let i = 0; i < contours.size(); i++) {
        const c = contours.get(i);
        const area = cv.contourArea(c);
        if (area > maxArea) {
          maxArea = area;
          largeContour = c;
        }
      }

      if (maxArea < 0) {
        return null;
      }

      // https://labs.eecs.tottori-u.ac.jp/sd/Member/oyamada/OpenCV/html/py_tutorials/py_imgproc/py_contours/py_contour_features/py_contour_features.html#id5
      const epsilon = 0.1 * cv.arcLength(largeContour, true);
      const quadrangle = new cv.Mat(largeContour.size(), largeContour.type());
      cv.approxPolyDP(largeContour, quadrangle, epsilon, true);

      contours.delete();
      hierarchy.delete();

      return quadrangle.size().height == 4 ? quadrangle : null;
    }

    /**
     * 枠を抜き出す
     * @param {cv.Mat} srcImg 元の画像
     * @param {cv.Mat} frame 枠の座標
     * @return {cv.Mat} 抜き出した画像
     */
    function extractFrame(srcImg, frame) {
      const points = [];

      for (let i = 0; i < frame.size().height; i++) {
        const row = frame.row(i);
        const x = row.data32S.at(0);
        const y = row.data32S.at(1);
        points.push([x, y]);
      }

      const sortedY = points.sort((a, b) => a[1] - b[1]);
      const [topLeft, topRight] = sortedY[0][0] < sortedY[1][0] ? [sortedY[0], sortedY[1]] : [sortedY[1], sortedY[0]];
      const [bottomLeft, bottomRight] = sortedY[2][0] < sortedY[3][0] ? [sortedY[2], sortedY[3]] : [sortedY[3], sortedY[2]];

      // 変換前の座標(左上から時計回り)
      const src = cv.matFromArray(4, 1, cv.CV_32FC2, [...topLeft, ...topRight, ...bottomRight, ...bottomLeft]);
      // 変換後の座標(変換前と対応させて左上から時計回り)
      const dst = cv.matFromArray(4, 1, cv.CV_32FC2, [0, 0, FRAME_SIZE - 1, 0, FRAME_SIZE - 1, FRAME_SIZE - 1, 0, FRAME_SIZE - 1]);
      const matrix = cv.getPerspectiveTransform(src, dst);
      src.delete();
      dst.delete();

      const frameImg = new cv.Mat(FRAME_SIZE, FRAME_SIZE, cv.CV_8UC4);
      cv.warpPerspective(srcImg, frameImg, matrix, new cv.Size(FRAME_SIZE, FRAME_SIZE));
      matrix.delete();

      return frameImg;
    }


    /**
     * 数字を読む
     * @return 読み取り結果
     */
    async function readDigit(srcCanvas, dstCanvas) {
      dstCanvas.width = srcCanvas.width;
      dstCanvas.height = srcCanvas.height;
      const ctx = dstCanvas.getContext('2d');
      ctx.drawImage(srcCanvas, 0, 0, srcCanvas.width, srcCanvas.height, 0, 0, srcCanvas.width, srcCanvas.width);

      ctx.strokeStyle = 'rgb(0 255 0)';
      ctx.fillStyle = 'rgb(0 255 0)';
      ctx.font = '16px sans-serif';
      ctx.textAlign = 'left';
      ctx.textBaseline = 'top';
      const pixel = ctx.getImageData(0, 0, dstCanvas.width, dstCanvas.height).data;
      const startPos = Math.floor(64 / 2);

      const worker = await Tesseract.createWorker('eng');
      worker.setParameters({ tessedit_char_whitelist: '0123456789' });

      const rows = [];
      for (let y = 0; y < 9; y++) {
        let cols = [];
        for (let x = 0; x < 9; x++) {
          const [countX, countY] = countNonZero(pixel, x * 64, y * 64);
          const left = findBorder(countX, startPos, -1);
          const right = findBorder(countX, startPos, 1);
          const top = findBorder(countY, startPos, -1);
          const bottom = findBorder(countY, startPos, 1);

          const result = await worker.recognize(dstCanvas,
            { rectangle: { top: top + y * 64, left: left + x * 64, width: right - left, height: bottom - top } },
            { text: true, blocks: true }
          );
          const text = result.data.text.trim();
          const digit = text.length === 0 ? '' : text;
          cols.push(digit);

          // 認識範囲の確認用の枠
          ctx.strokeRect(left + x * 64, top + y * 64, right - left, bottom - top);
          ctx.fillText(digit, left + x * 64 ,top + y * 64);

        }
        rows.push(cols);
      }
      console.log(rows);
    }

    /**
     * 0ではないピクセルデータを数える
     * @param {pixelData}
     * @param {x}
     * @param {y}
     */
    function countNonZero(pixelData, x, y) {
      const countX = [];
      const countY = [];
      for (let i = 0; i < 64; i++) {
        countX[i] = 0;
        countY[i] = 0;
      }
      for (let i = 0; i < 64; i++) {
        for (let j = 0; j < 64; j++) {
          const baseIndex = ((y + i) * FRAME_SIZE + (x + j)) * 4;
          const r = pixelData[baseIndex];
          const g = pixelData[baseIndex + 1];
          const b = pixelData[baseIndex + 2];
          if (r !== 0 || g !== 0 || b !== 0) {
            countX[j]++;
            countY[i]++;
          }
        }
      }
      return [countX, countY];
    }

    function findBorder(countArray, start, step) {
      const ZERO_THREASHOLD = 8;
      const PADDING = 8;
      let zeroCount = 0;
      let padding = 0
      for (let i = start; (i >= 0 && i < countArray.length); i += step) {
        if (countArray[i] <= ZERO_THREASHOLD) {
          zeroCount++;
          if (zeroCount >= PADDING)
            padding = i;
        } else {
          zeroCount = 0
        }
      }

      return padding;
    }

  </script>
</body>

</html>